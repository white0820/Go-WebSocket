{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7414502a-4532-4da3-aef0-71aac4d0d4dd",
      "metadata": {
        "id": "7414502a-4532-4da3-aef0-71aac4d0d4dd"
      },
      "source": [
        "# How to load web pages\n",
        "\n",
        "This guide covers how to [load](/docs/concepts/document_loaders/) web pages into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.\n",
        "\n",
        "LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\n",
        "\n",
        "- [Simple and fast](/docs/how_to/document_loader_web#simple-and-fast-text-extraction) parsing, in which we recover one `Document` per web page with its content represented as a \"flattened\" string;\n",
        "- [Advanced](/docs/how_to/document_loader_web#advanced-parsing) parsing, in which we recover multiple `Document` objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\n",
        "\n",
        "## Setup\n",
        "\n",
        "For the \"simple and fast\" parsing, we will need `langchain-community` and the `beautifulsoup4` library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "89bc7be9-ab50-4c5a-860a-deee7b469f67",
      "metadata": {
        "id": "89bc7be9-ab50-4c5a-860a-deee7b469f67",
        "outputId": "7a81ec9c-80e5-48d2-ff4a-91934dca6b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-community beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07f5ca3-e2b7-4d9c-b1f2-7547856cbdf7",
      "metadata": {
        "id": "a07f5ca3-e2b7-4d9c-b1f2-7547856cbdf7"
      },
      "source": [
        "For advanced parsing, we will use `langchain-unstructured`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a3ef1fc-dfde-4814-b7f6-b6c0c649f044",
      "metadata": {
        "id": "8a3ef1fc-dfde-4814-b7f6-b6c0c649f044"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef11005-1bd0-43a3-8d52-ea823c830c34",
      "metadata": {
        "id": "4ef11005-1bd0-43a3-8d52-ea823c830c34"
      },
      "source": [
        "## Simple and fast text extraction\n",
        "\n",
        "If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of `Document` objects -- one per page -- containing a single string of the page's text. Under the hood it uses the `beautifulsoup4` Python library.\n",
        "\n",
        "LangChain document loaders implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document objects`. We will use these below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7faeccbc-4e56-4b88-99db-2274ed0680c1",
      "metadata": {
        "id": "7faeccbc-4e56-4b88-99db-2274ed0680c1",
        "outputId": "f9686c7c-6447-4d94-c1d5-da0c94e2fa1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  8.79it/s]\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "page_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[page_url])\n",
        "docs = []\n",
        "async for doc in loader.alazy_load():\n",
        "    docs.append(doc)\n",
        "\n",
        "assert len(docs) == 1\n",
        "doc = docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21199a0d-3bd2-4410-a060-763649b14691",
      "metadata": {
        "id": "21199a0d-3bd2-4410-a060-763649b14691",
        "outputId": "1461771d-0afe-4003-9cd6-11dffd883275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': 'https://python.langchain.com/docs/how_to/chatbots_memory/', 'title': 'How to add memory to chatbots | ü¶úÔ∏èüîó LangChain', 'description': 'A key feature of chatbots is their ability to use the content of previous conversational turns as context. This state management can take several forms, including:', 'language': 'en'}\n",
            "\n",
            "How to add memory to chatbots | ü¶úÔ∏èüîó LangChain\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval A\n"
          ]
        }
      ],
      "source": [
        "print(f\"{doc.metadata}\\n\")\n",
        "print(doc.page_content[:500].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23189e91-5237-4a9e-a4bb-cb79e130c364",
      "metadata": {
        "id": "23189e91-5237-4a9e-a4bb-cb79e130c364"
      },
      "source": [
        "This is essentially a dump of the text from the page's HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired `<div>` classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4211b1a6-e636-415b-a556-ae01969399a7",
      "metadata": {
        "id": "4211b1a6-e636-415b-a556-ae01969399a7",
        "outputId": "91676321-4f6d-4a9a-8eec-1b9d3febc5a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00, 13.07it/s]\n"
          ]
        }
      ],
      "source": [
        "loader = WebBaseLoader(\n",
        "    web_paths=[page_url],\n",
        "    bs_kwargs={\n",
        "        \"parse_only\": bs4.SoupStrainer(class_=\"theme-doc-markdown markdown\"),\n",
        "    },\n",
        "    bs_get_text_kwargs={\"separator\": \" | \", \"strip\": True},\n",
        ")\n",
        "\n",
        "docs = []\n",
        "async for doc in loader.alazy_load():\n",
        "    docs.append(doc)\n",
        "\n",
        "assert len(docs) == 1\n",
        "doc = docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7edf6ed0-e22f-4c64-b986-8ba019c14757",
      "metadata": {
        "id": "7edf6ed0-e22f-4c64-b986-8ba019c14757",
        "outputId": "35bfe5db-e390-4197-a610-f45ea883e14a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': 'https://python.langchain.com/docs/how_to/chatbots_memory/'}\n",
            "\n",
            "How to add memory to chatbots | A key feature of chatbots is their ability to use the content of previous conversational turns as context. This state management can take several forms, including: | Simply stuffing previous messages into a chat model prompt. | The above, but trimming old messages to reduce the amount of distracting information the model has to deal with. | More complex modifications like synthesizing summaries for long running conversations. | We'll go into more detail on a few t\n"
          ]
        }
      ],
      "source": [
        "print(f\"{doc.metadata}\\n\")\n",
        "print(doc.page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab1ba2b-3b22-4c5d-8ad3-f6809d075d26",
      "metadata": {
        "id": "6ab1ba2b-3b22-4c5d-8ad3-f6809d075d26",
        "outputId": "7b7886a5-76b1-4648-d0f1-cdf44529f6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a greeting. Nemo then asks the AI how it is doing, and the AI responds that it is fine.'), | HumanMessage(content='What did I say my name was?'), | AIMessage(content='You introduced yourself as Nemo. How can I assist you today, Nemo?')] | Note that invoking the chain again will generate another summary generated from the initial summary plus new messages and so on. You could also design a hybrid approach where a certain number of messages are retained in chat history while others are summarized.\n"
          ]
        }
      ],
      "source": [
        "print(doc.page_content[-500:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a411144-a234-4505-956c-930d399ffefb",
      "metadata": {
        "id": "0a411144-a234-4505-956c-930d399ffefb"
      },
      "source": [
        "Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.\n",
        "\n",
        "We can parameterize `WebBaseLoader` with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) for detail."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdfc8f68-2b08-4a6c-9705-c17e6deaf411",
      "metadata": {
        "id": "cdfc8f68-2b08-4a6c-9705-c17e6deaf411"
      },
      "source": [
        "## Advanced parsing\n",
        "\n",
        "This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one `Document` per page and controlling its content via BeautifulSoup, we generate multiple `Document` objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.\n",
        "\n",
        "Under the hood it uses the `langchain-unstructured` library. See the [integration docs](/docs/integrations/document_loaders/unstructured_file/) for more information about using [Unstructured](https://docs.unstructured.io/welcome) with LangChain."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "ANU3EPPnhxgM"
      },
      "id": "ANU3EPPnhxgM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a6bbfef-ebd5-4357-a7f5-9c989dda092d",
      "metadata": {
        "id": "7a6bbfef-ebd5-4357-a7f5-9c989dda092d",
        "outputId": "c31f4b85-61bd-4d98-ff01-76fa47a7de84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "unstructured package not found, please install it with `pip install unstructured`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_unstructured/document_loaders.py\u001b[0m in \u001b[0;36m_elements_via_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0munstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartition\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f4eb46bdce69>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/document_loaders/base.py\u001b[0m in \u001b[0;36malazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecutor_or_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor_or_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# Use default executor with context copied from current context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         return await asyncio.get_running_loop().run_in_executor(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Callable[..., T]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0;31m# StopIteration can't be set on an asyncio.Future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_unstructured/document_loaders.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Call _UnstructuredBaseLoader normally since file and file_path are not lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_unstructured/document_loaders.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_process_elements_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_processors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         )\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melements_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_unstructured/document_loaders.py\u001b[0m in \u001b[0;36m_elements_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements_via_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_elements_to_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements_via_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_unstructured/document_loaders.py\u001b[0m in \u001b[0;36m_elements_via_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0munstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartition\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0;34m\"unstructured package not found, please install it with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;34m\"`pip install unstructured`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: unstructured package not found, please install it with `pip install unstructured`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain_unstructured import UnstructuredLoader\n",
        "\n",
        "page_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"\n",
        "loader = UnstructuredLoader(web_url=page_url)\n",
        "\n",
        "docs = []\n",
        "async for doc in loader.alazy_load():\n",
        "    docs.append(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a600b0-fcd2-4074-80b6-a1dd2c0d9235",
      "metadata": {
        "id": "53a600b0-fcd2-4074-80b6-a1dd2c0d9235"
      },
      "source": [
        "Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "198b7469-587f-4a80-a49f-440e6157b241",
      "metadata": {
        "id": "198b7469-587f-4a80-a49f-440e6157b241",
        "outputId": "ca69cbc1-6882-46e8-c908-5f2f9668d915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How to add memory to chatbots\n",
            "A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:\n",
            "Simply stuffing previous messages into a chat model prompt.\n",
            "The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.\n",
            "More complex modifications like synthesizing summaries for long running conversations.\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 2747\n"
          ]
        }
      ],
      "source": [
        "for doc in docs[:5]:\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f4254b5-5e3b-45c4-9cd0-7ed753687783",
      "metadata": {
        "id": "3f4254b5-5e3b-45c4-9cd0-7ed753687783"
      },
      "source": [
        "### Extracting content from specific sections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627d9b7a-31fe-4923-bc9a-4b0caae1d760",
      "metadata": {
        "id": "627d9b7a-31fe-4923-bc9a-4b0caae1d760"
      },
      "source": [
        "Each `Document` object represents an element of the page. Its metadata contains useful information, such as its category:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa19a61-a53d-42e0-a01a-7ea99fc40810",
      "metadata": {
        "id": "2fa19a61-a53d-42e0-a01a-7ea99fc40810",
        "outputId": "784e9ce5-469b-4434-88cb-a0b8d2cda835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: How to add memory to chatbots\n",
            "NarrativeText: A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:\n",
            "ListItem: Simply stuffing previous messages into a chat model prompt.\n",
            "ListItem: The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.\n",
            "ListItem: More complex modifications like synthesizing summaries for long running conversations.\n"
          ]
        }
      ],
      "source": [
        "for doc in docs[:5]:\n",
        "    print(f'{doc.metadata[\"category\"]}: {doc.page_content}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca0f8025-58b8-4d2a-95aa-124d7a8ee812",
      "metadata": {
        "id": "ca0f8025-58b8-4d2a-95aa-124d7a8ee812"
      },
      "source": [
        "Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding `Document` objects.\n",
        "\n",
        "As an example, below we load the content of the \"Setup\" sections for two web pages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "793018fd-1365-4a8a-8690-6d51dad2e1cf",
      "metadata": {
        "id": "793018fd-1365-4a8a-8690-6d51dad2e1cf"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "async def _get_setup_docs_from_url(url: str) -> List[Document]:\n",
        "    loader = UnstructuredLoader(web_url=url)\n",
        "\n",
        "    setup_docs = []\n",
        "    parent_id = -1\n",
        "    async for doc in loader.alazy_load():\n",
        "        if doc.metadata[\"category\"] == \"Title\" and doc.page_content.startswith(\"Setup\"):\n",
        "            parent_id = doc.metadata[\"element_id\"]\n",
        "        if doc.metadata.get(\"parent_id\") == parent_id:\n",
        "            setup_docs.append(doc)\n",
        "\n",
        "    return setup_docs\n",
        "\n",
        "\n",
        "page_urls = [\n",
        "    \"https://python.langchain.com/docs/how_to/chatbots_memory/\",\n",
        "    \"https://python.langchain.com/docs/how_to/chatbots_tools/\",\n",
        "]\n",
        "setup_docs = []\n",
        "for url in page_urls:\n",
        "    page_setup_docs = await _get_setup_docs_from_url(url)\n",
        "    setup_docs.extend(page_setup_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67e0745-abfc-4baa-94b3-2e8815bfa52a",
      "metadata": {
        "id": "a67e0745-abfc-4baa-94b3-2e8815bfa52a",
        "outputId": "b314e624-d620-4e22-b26e-30547bf53d21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'https://python.langchain.com/docs/how_to/chatbots_memory/': \"You'll need to install a few packages, and have your OpenAI API key set as an environment variable named OPENAI_API_KEY:\\n%pip install --upgrade --quiet langchain langchain-openai\\n\\n# Set env var OPENAI_API_KEY or load from a .env file:\\nimport dotenv\\n\\ndotenv.load_dotenv()\\n[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\\nYou should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m\\n[0mNote: you may need to restart the kernel to use updated packages.\\n\",\n",
              " 'https://python.langchain.com/docs/how_to/chatbots_tools/': \"For this guide, we'll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\\nYou'll need to sign up for an account on the Tavily website, and install the following packages:\\n%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\\n\\n# Set env var OPENAI_API_KEY or load from a .env file:\\nimport dotenv\\n\\ndotenv.load_dotenv()\\nYou will also need your OpenAI key set as OPENAI_API_KEY and your Tavily API key set as TAVILY_API_KEY.\\n\"}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "setup_text = defaultdict(str)\n",
        "\n",
        "for doc in setup_docs:\n",
        "    url = doc.metadata[\"url\"]\n",
        "    setup_text[url] += f\"{doc.page_content}\\n\"\n",
        "\n",
        "dict(setup_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd42892-24a6-4969-92c8-c928680be9b5",
      "metadata": {
        "id": "5cd42892-24a6-4969-92c8-c928680be9b5"
      },
      "source": [
        "### Vector search over page content\n",
        "\n",
        "Once we have loaded the page contents into LangChain `Document` objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI [embeddings](/docs/concepts/embedding_models), although any LangChain embeddings model will suffice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6cbb01-6e0d-418f-9f76-2031622bebb0",
      "metadata": {
        "id": "5a6cbb01-6e0d-418f-9f76-2031622bebb0"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598e612c-180d-494d-8caa-761c89f84eae",
      "metadata": {
        "id": "598e612c-180d-494d-8caa-761c89f84eae"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eeaeb54-ea03-4634-8a79-b60c22ab2b66",
      "metadata": {
        "id": "5eeaeb54-ea03-4634-8a79-b60c22ab2b66",
        "outputId": "f6f73aed-801b-4c3f-c16a-5af3abbdb47c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page https://python.langchain.com/docs/how_to/chatbots_tools/: You'll need to sign up for an account on the Tavily website, and install the following packages:\n",
            "\n",
            "Page https://python.langchain.com/docs/how_to/chatbots_tools/: For this guide, we'll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vector_store = InMemoryVectorStore.from_documents(setup_docs, OpenAIEmbeddings())\n",
        "retrieved_docs = vector_store.similarity_search(\"Install Tavily\", k=2)\n",
        "for doc in retrieved_docs:\n",
        "    print(f'Page {doc.metadata[\"url\"]}: {doc.page_content[:300]}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67be9c94-dbde-4fdd-87d0-e83ed6066d2b",
      "metadata": {
        "id": "67be9c94-dbde-4fdd-87d0-e83ed6066d2b"
      },
      "source": [
        "## Other web page loaders\n",
        "\n",
        "For a list of available LangChain web page loaders, please see [this table](/docs/integrations/document_loaders/#webpages)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}